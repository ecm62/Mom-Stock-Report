import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
import requests
from deep_translator import GoogleTranslator
from datetime import datetime
from streamlit_autorefresh import st_autorefresh

# --- 1. é é¢èˆ‡è‡ªå‹•æ›´æ–° ---
st.set_page_config(layout="wide", page_title="é˜¿ç¾çš„è‚¡æµ·é¡§å•", initial_sidebar_state="collapsed")
st_autorefresh(interval=5 * 60 * 1000, key="auto_refresh") # 5åˆ†é˜è‡ªå‹•åˆ·æ–°

# --- 2. GAS API ---
GAS_URL = "https://script.google.com/macros/s/AKfycbwTsM79MMdedizvIcIn7tgwT81VIhj87WM-bvR45QgmMIUsIemmyR_FzMvG3v5LEHEvPw/exec"

# --- 3. åª’é«”é—œéµå­—å­—å…¸ ---
MEDIA_PRESETS = {
    "é›…è™": "https://finance.yahoo.com/news/rssindex",
    "é‰…äº¨": "https://news.cnyes.com/rss/cat/headline",
    "è¯åˆ": "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
    "ç¶“æ¿Ÿ": "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
    "moneydj": "https://www.moneydj.com/rss/xa/mdj_xa_rss.xml",
    "å•†å‘¨": "https://www.businessweekly.com.tw/rss/latest",
    "ç§‘æŠ€": "https://technews.tw/feed/"
}

# --- 4. CSS å„ªåŒ– (æ–°èæ¨™é¡Œé€£çµåŒ–) ---
st.markdown("""
    <style>
    html, body, [class*="css"] { font-family: "Microsoft JhengHei", sans-serif; }
    
    /* è‚¡ç¥¨å¡ç‰‡ */
    .compact-card {
        border: 1px solid #ddd; border-radius: 6px;
        padding: 5px 2px; text-align: center;
        background: white; margin-bottom: 5px;
        box-shadow: 1px 1px 2px rgba(0,0,0,0.1);
        min-height: 85px;
    }
    .compact-name { font-size: 15px !important; font-weight: 900; color: #333; margin: 0; line-height: 1.2; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;}
    .compact-price { font-size: 18px !important; font-weight: bold; margin: 2px 0; line-height: 1.2;}
    
    /* PChome é¢¨æ ¼æ¦œå–® */
    .rank-title {
        font-size: 18px; font-weight: 900; color: #fff;
        background: linear-gradient(90deg, #d32f2f, #ef5350);
        padding: 8px; border-radius: 5px 5px 0 0;
        margin-top: 15px; text-align: center;
    }
    .rank-box {
        border: 1px solid #ef5350; border-top: none;
        border-radius: 0 0 5px 5px; padding: 5px;
        background: #fff; margin-bottom: 15px;
    }
    .rank-row { display: flex; justify-content: space-between; align-items: center; padding: 8px 5px; border-bottom: 1px dashed #eee; }
    .rank-name { font-size: 16px; font-weight: bold; color: #333; }
    
    /* ç”¢æ¥­æ–°èåˆ†é¡æ¨™é¡Œ */
    .news-category-header {
        background-color: #e3f2fd; color: #1565c0;
        padding: 10px 15px; border-left: 6px solid #1565c0;
        font-size: 22px !important; font-weight: 900;
        margin-top: 30px; margin-bottom: 15px;
        border-radius: 0 10px 10px 0;
    }
    
    /* æ–°èè¶…é€£çµæ¨£å¼ */
    .news-item { padding: 12px 5px; border-bottom: 1px solid #eee; }
    .news-link-text {
        text-decoration: none; color: #2c3e50;
        font-size: 20px !important; font-weight: 700;
        line-height: 1.5; display: block; margin-bottom: 5px;
    }
    .news-link-text:hover { color: #d32f2f; text-decoration: underline; }
    .news-meta { font-size: 13px; color: #888; }
    
    div[data-testid="column"] { padding: 0 2px !important; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‘µ é˜¿ç¾çš„è‚¡æµ·é¡§å•")
st.caption(f"ç”¢æ¥­æ–°èè‡ªå‹•ç¯©é¸ç³»çµ± | æ›´æ–°ï¼š{datetime.now().strftime('%H:%M')}")

# --- 5. ç²¾ç´°åŒ–ç”¢æ¥­é—œéµå­—çŸ©é™£ (The Filtering Engine) ---
# é€™æ˜¯ç³»çµ±çš„å¤§è…¦ï¼Œè² è²¬æŠŠæ–°èæ­¸é¡åˆ°æ­£ç¢ºçš„æŠ½å±œ
KEYWORD_MAPPING = {
    "ğŸ¤– AI èˆ‡åŠå°é«”": ["å°ç©é›»", "è¯é›»", "è¯ç™¼ç§‘", "æ—¥æœˆå…‰", "AI", "åŠå°é«”", "æ™¶åœ“", "è¼é”", "NVIDIA", "CoWoS", "å…ˆé€²å°è£", "ä¼ºæœå™¨", "ç·¯å‰µ", "å»£é”", "æŠ€å˜‰"],
    "ğŸ—ï¸ é‹¼éµèˆ‡æ°´æ³¥": ["ä¸­é‹¼", "ä¸­é´»", "å¤§æˆé‹¼", "é‹¼éµ", "å°æ³¥", "äºæ³¥", "æ°´æ³¥", "ç»é™¶", "è±èˆˆ", "é‹¼åƒ¹", "åŸºå»º"],
    "ğŸš¢ èˆªé‹èˆ‡é‹è¼¸": ["é•·æ¦®", "é™½æ˜", "è¬æµ·", "èˆªé‹", "è²¨æ«ƒ", "æ•£è£", "BDI", "èˆªç©º", "è¯èˆª", "é•·æ¦®èˆª", "æ˜Ÿå®‡", "é‹åƒ¹"],
    "ğŸš— æ±½è»Šèˆ‡ä¾›æ‡‰éˆ": ["è£•éš†", "å’Œæ³°è»Š", "ä¸­è¯è»Š", "æ±½è»Š", "é›»å‹•è»Š", "ç‰¹æ–¯æ‹‰", "Tesla", "é´»è¯", "å……é›»æ¨", "è»Šç”¨", "æ±é™½", "å ¤ç¶­è¥¿", "AM"],
    "ğŸ’° é‡‘èèˆ‡éŠ€è¡Œ": ["é‡‘æ§", "éŠ€è¡Œ", "å£½éšª", "å¯Œé‚¦", "åœ‹æ³°", "ä¸­ä¿¡", "ç‰å±±", "å…†è±", "å°æ–°", "å‡æ¯", "é™æ¯", "è‚¡åˆ©", "é…æ¯"],
    "âš¡ é‡é›»èˆ‡ç¶ èƒ½": ["è¯åŸ", "å£«é›»", "ä¸­èˆˆé›»", "äºåŠ›", "é‡é›»", "ç¶ èƒ½", "é¢¨é›»", "å¤ªé™½èƒ½", "å„²èƒ½", "å°é›»", "é›»ç¶²"],
    "ğŸ’Š ç”ŸæŠ€èˆ‡é˜²ç–«": ["ç”ŸæŠ€", "è—¥", "ç–«è‹—", "åˆä¸€", "é«˜ç«¯", "ç¾æ™‚", "ä¿ç‘", "é†«ç™‚"],
    "ğŸ  ç‡Ÿå»ºèˆ‡æˆ¿ç”¢": ["ç‡Ÿå»º", "æˆ¿åœ°ç”¢", "æˆ¿å¸‚", "é é›„", "èˆˆå¯Œç™¼", "åœ‹ç”¢", "é å”®å±‹"]
}

# ç†±é–€æ¦œå–®
HOT_LISTS = {
    "ğŸ”¥ ç†±é–€è¨è«–": ["2330.TW", "2317.TW", "3231.TW", "2382.TW", "2603.TW", "2609.TW"], 
    "ğŸ’ äººæ°£ ETF": ["00878.TW", "0056.TW", "0050.TW", "00919.TW", "00929.TW", "00940.TW"], 
    "ğŸ’¡ ç„¦é»æ¦‚å¿µ": ["1519.TW", "1513.TW", "2308.TW", "2454.TW", "6669.TW", "2376.TW"] 
}

# æ¼¢åŒ–å­—å…¸
STOCK_MAP = {
    "00878": "åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯", "2301": "å…‰å¯¶ç§‘", "2308": "å°é”é›»", "2412": "ä¸­è¯é›»", 
    "2476": "é‰…ç¥¥", "2884": "ç‰å±±é‡‘", "2892": "ç¬¬ä¸€é‡‘", "3034": "è¯è© ", 
    "3035": "æ™ºåŸ", "3363": "ä¸Šè©®", "3715": "å®šç©æŠ•æ§", "4772": "å°ç‰¹åŒ–", 
    "5880": "åˆåº«é‡‘", "6191": "ç²¾æˆç§‘", "6761": "ç©©å¾—", "6788": "è¯æ™¯é›»", 
    "8926": "å°æ±½é›»", "2330": "å°ç©é›»", "2317": "é´»æµ·", "2603": "é•·æ¦®", 
    "2609": "é™½æ˜", "2615": "è¬æµ·", "2454": "è¯ç™¼ç§‘", "3231": "ç·¯å‰µ",
    "0056": "å…ƒå¤§é«˜è‚¡æ¯", "0050": "å…ƒå¤§å°ç£50", "00919": "ç¾¤ç›Šå°ç£ç²¾é¸", "00929": "å¾©è¯ç§‘æŠ€å„ªæ¯",
    "00940": "å…ƒå¤§å°ç£åƒ¹å€¼", "1519": "è¯åŸ", "1513": "ä¸­èˆˆé›»", "1503": "å£«é›»", "2382": "å»£é”", "6669": "ç·¯ç©",
    "2376": "æŠ€å˜‰", "2002": "ä¸­é‹¼", "1101": "å°æ³¥", "2201": "è£•éš†"
}

# --- 6. æ ¸å¿ƒå‡½æ•¸ ---

def get_list_from_cloud(list_type):
    try:
        response = requests.get(GAS_URL, params={"action": "read", "type": list_type}, timeout=5)
        return response.json() or []
    except: return []

def update_cloud(action, code, list_type, price="0"):
    try: requests.get(GAS_URL, params={"action": action, "code": code, "type": list_type, "price": price}, timeout=2)
    except: pass

def get_name(ticker):
    code = ticker.split(".")[0]
    return STOCK_MAP.get(code, code)

def get_stock_data(ticker_list):
    if not ticker_list: return pd.DataFrame()
    valid = [t for t in ticker_list if t.strip()]
    if not valid: return pd.DataFrame()
    data = []
    try:
        stocks = yf.Tickers(" ".join(valid))
        for t in valid:
            try:
                info = stocks.tickers[t].history(period="5d")
                if len(info) > 0:
                    price = info['Close'].iloc[-1]
                    prev = info['Close'].iloc[-2] if len(info) > 1 else price
                    pct = ((price - prev) / prev) * 100
                    color = "#e53935" if pct >= 0 else "#43a047"
                    sign = "â–²" if pct >= 0 else "â–¼"
                    data.append({
                        "name": get_name(t), "code": t.replace(".TW", "").replace(".TWO", ""),
                        "full_code": t, "price": f"{price:.2f}",
                        "pct": f"{pct:.2f}%", "color": color, "sign": sign
                    })
            except: continue
    except: pass
    return pd.DataFrame(data)

@st.cache_data(ttl=300)
def fetch_and_filter_news(rss_urls):
    # å»ºç«‹ç©ºçš„åˆ†é¡æ¡¶
    buckets = {key: [] for key in KEYWORD_MAPPING.keys()}
    buckets["ğŸŒ å…¶ä»–é ­æ¢"] = []
    
    seen_titles = set()
    
    # æ“´å……é è¨­æ–°èæºï¼šåŠ å…¥é‰…äº¨é ­æ¢ã€é‰…äº¨å°è‚¡ã€MoneyDJ
    if not rss_urls:
        rss_urls = [
            "https://news.cnyes.com/rss/cat/headline", # é ­æ¢
            "https://news.cnyes.com/rss/cat/200",      # å°è‚¡æ–°è
            "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
            "https://www.moneydj.com/rss/xa/mdj_xa_rss.xml"
        ]

    for url in rss_urls:
        try:
            feed = feedparser.parse(url)
            # æŠ“å–æ•¸é‡æå‡åˆ° 40 å‰‡ï¼Œå¢åŠ åŒ¹é…æˆåŠŸç‡
            for entry in feed.entries[:40]: 
                title = entry.title
                if title[:10] in seen_titles: continue
                seen_titles.add(title[:10])
                
                # ç°¡å–®ç¿»è­¯è‹±æ–‡
                if "yahoo" in url and sum(1 for c in title if '\u4e00' <= c <= '\u9fff') < len(title)*0.3:
                     try: title = GoogleTranslator(source='auto', target='zh-TW').translate(title)
                     except: pass
                
                item = {
                    "title": title, 
                    "link": entry.link, 
                    "date": entry.get('published', '')[:16], 
                    "src": feed.feed.get('title', 'æ–°è')
                }
                
                # --- é—œéµå­—åŒ¹é…å¼•æ“ ---
                matched = False
                for category, keywords in KEYWORD_MAPPING.items():
                    if any(kw in title for kw in keywords):
                        buckets[category].append(item)
                        matched = True
                        break # æ­¸é¡åˆ°ç¬¬ä¸€å€‹ç¬¦åˆçš„åˆ†é¡
                
                if not matched:
                    buckets["ğŸŒ å…¶ä»–é ­æ¢"].append(item)
                    
        except: continue
    return buckets

# --- 7. ä»‹é¢ä½ˆå±€ ---

with st.sidebar:
    st.header("âš™ï¸ ç®¡ç†å“¡å¾Œå°")
    
    with st.expander("â• æ–°å¢åˆ°ã€åº«å­˜è‚¡ã€‘"):
        inv_code = st.text_input("ä»£ç¢¼", key="add_inv", placeholder="å¦‚ 2330.TW")
        if st.button("åŠ å…¥åº«å­˜"):
            update_cloud("add", inv_code.upper(), "inventory")
            st.cache_data.clear(); st.rerun()
            
    with st.expander("â• æ–°å¢åˆ°ã€è§€å¯Ÿåå–®ã€‘"):
        watch_code = st.text_input("ä»£ç¢¼", key="add_watch", placeholder="å¦‚ 2603.TW")
        if st.button("åŠ å…¥è§€å¯Ÿ"):
            update_cloud("add", watch_code.upper(), "watchlist")
            st.cache_data.clear(); st.rerun()

    with st.expander("ğŸ“° æ–°å¢ã€æ–°èé »é“ã€‘"):
        st.info("è¼¸å…¥ã€Œé‰…äº¨ã€ã€ã€Œé›…è™ã€æˆ–ç¶²å€")
        new_rss_input = st.text_input("åª’é«”åç¨±", key="add_rss_input")
        if st.button("åŠ å…¥é »é“"):
            url = new_rss_input
            if new_rss_input in MEDIA_PRESETS: url = MEDIA_PRESETS[new_rss_input]
            elif "http" not in new_rss_input and new_rss_input in MEDIA_PRESETS: url = MEDIA_PRESETS[new_rss_input] # ç°¡æ˜“é˜²å‘†
            
            update_cloud("add", url, "news")
            st.success("å·²åŠ å…¥")
            st.cache_data.clear(); st.rerun()
        
        feeds = get_list_from_cloud("news")
        if feeds:
            st.write("å·²åŠ å…¥é »é“ï¼š")
            for f in feeds:
                c1,c2=st.columns([4,1])
                c1.text(f[:20]+"...")
                if c2.button("åˆª", key=f"d_{f}"): update_cloud("remove",f,"news"); st.rerun()

    if st.button("ğŸ”„ å¼·åˆ¶æ›´æ–°"): st.cache_data.clear(); st.rerun()

# === ç¬¬ä¸€å±¤ï¼šğŸ’° åª½åª½çš„åº«å­˜ (6æ¬„) ===
c1, c2 = st.columns([3, 1])
with c1: st.subheader("ğŸ’° åª½åª½çš„åº«å­˜")
with c2: 
    if st.button("æ›´æ–°"): st.cache_data.clear(); st.rerun()

inv_list = get_list_from_cloud("inventory")
if inv_list:
    df = get_stock_data(inv_list)
    cols = st.columns(6)
    for i, row in df.iterrows():
        with cols[i%6]:
            st.markdown(f"""
            <div class="compact-card" style="border-left: 4px solid {row['color']};">
                <div class="compact-name" title="{row['name']}">{row['name']}</div>
                <div class="compact-price" style="color:{row['color']}">{row['price']}</div>
                <div style="font-size:12px; font-weight:bold; color:{row['color']}">{row['sign']} {row['pct']}</div>
            </div>""", unsafe_allow_html=True)
            if st.button("âœ–", key=f"d_{row['code']}"): update_cloud("remove", row['full_code'], "inventory"); st.rerun()

# === ç¬¬äºŒå±¤ï¼šğŸ‘€ æœ‰èˆˆè¶£çš„è‚¡ç¥¨ (6æ¬„) ===
st.subheader("ğŸ‘€ æœ‰èˆˆè¶£çš„è‚¡ç¥¨")
watch_list = get_list_from_cloud("watchlist")
if watch_list:
    df_w = get_stock_data(watch_list)
    cols2 = st.columns(6)
    for i, row in df_w.iterrows():
        with cols2[i%6]:
            st.markdown(f"""<div class="compact-card"><div class="compact-name">{row['name']}</div><div class="compact-price" style="color:{row['color']}">{row['price']}</div></div>""", unsafe_allow_html=True)
            if st.button("âœ–", key=f"dw_{row['code']}"): update_cloud("remove", row['full_code'], "watchlist"); st.rerun()
else:
    st.info("ç›®å‰æ²’æœ‰è§€å¯Ÿåå–®ï¼Œè«‹å¾å·¦å´æ–°å¢ã€‚")

# === ç¬¬ä¸‰å±¤ï¼šğŸ† å¸‚å ´ç†±é–€æˆ°æƒ…å®¤ ===
st.markdown("---")
st.subheader("ğŸ† å¸‚å ´ç†±é–€æˆ°æƒ…å®¤")

hot_cols = st.columns(3)
idx = 0
for title, tickers in HOT_LISTS.items():
    with hot_cols[idx]:
        st.markdown(f'<div class="rank-title">{title}</div>', unsafe_allow_html=True)
        df_hot = get_stock_data(tickers)
        html = '<div class="rank-box">'
        for _, row in df_hot.iterrows():
            html += f"""
            <div class="rank-row">
                <span class="rank-name">{row['name']}</span>
                <span class="rank-price" style="color:{row['color']}">{row['sign']} {row['price']}</span>
            </div>"""
        html += '</div>'
        st.markdown(html, unsafe_allow_html=True)
    idx += 1

# === ç¬¬å››å±¤ï¼šğŸ“° è‡ªå‹•åˆ†é¡ç”¢æ¥­æ–°è (ç€‘å¸ƒæµ) ===
st.markdown("---")
st.subheader("ğŸ—ï¸ ç”¢æ¥­æ–°èå¿«é (AI è‡ªå‹•åˆ†é¡)")

# æŠ“å–é›²ç«¯ + é è¨­ RSS
custom_rss = get_list_from_cloud("news")
active_rss = custom_rss if custom_rss else []

with st.spinner("æ­£åœ¨ç‚ºåª½åª½æœå°‹å„å¤§å ±ï¼Œéæ¿¾ç”¢æ¥­æ–°è..."):
    # å‘¼å«éæ¿¾å‡½æ•¸
    news_buckets = fetch_and_filter_news(active_rss)

# å®šç¾©é¡¯ç¤ºé †åº
display_order = [
    "ğŸ¤– AI èˆ‡åŠå°é«”", "ğŸ—ï¸ é‹¼éµèˆ‡æ°´æ³¥", "ğŸš— æ±½è»Šèˆ‡ä¾›æ‡‰éˆ", 
    "ğŸš¢ èˆªé‹èˆ‡é‹è¼¸", "âš¡ é‡é›»èˆ‡ç¶ èƒ½", "ğŸ’° é‡‘èèˆ‡éŠ€è¡Œ", 
    "ğŸ’Š ç”ŸæŠ€èˆ‡é˜²ç–«", "ğŸ  ç‡Ÿå»ºèˆ‡æˆ¿ç”¢", "ğŸŒ å…¶ä»–é ­æ¢"
]

for category in display_order:
    items = news_buckets.get(category, [])
    # åªæœ‰ç•¶è©²é¡åˆ¥æœ‰æ–°èæ™‚æ‰é¡¯ç¤ºï¼Œé¿å…ç‰ˆé¢ç©ºç™½
    if items:
        st.markdown(f'<div class="news-category-header">{category}</div>', unsafe_allow_html=True)
        
        # é¡¯ç¤ºè©²é¡åˆ¥çš„æ–°è (æ¨™é¡Œå³é€£çµ)
        for n in items[:6]: # æ¯é¡æœ€å¤šé¡¯ç¤º6å‰‡ï¼Œé¿å…æ»‘ä¸åˆ°åº•
            st.markdown(f"""
            <div class="news-item">
                <a href="{n['link']}" target="_blank" class="news-link-text">
                    {n['title']}
                </a>
                <div class="news-meta">
                    {n['src']} â€¢ {n['date']}
                </div>
            </div>
            """, unsafe_allow_html=True)

st.markdown("<br><br>", unsafe_allow_html=True)
