import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
import requests
from deep_translator import GoogleTranslator
from datetime import datetime
from streamlit_autorefresh import st_autorefresh  # å¼•å…¥è‡ªå‹•åˆ·æ–°å¥—ä»¶

# --- 1. é é¢èˆ‡è‡ªå‹•æ›´æ–°è¨­å®š ---
st.set_page_config(layout="wide", page_title="é˜¿ç¾çš„è‚¡æµ·é¡§å•", initial_sidebar_state="collapsed")

# ã€é—œéµåŠŸèƒ½ã€‘è¨­å®šæ¯ 5 åˆ†é˜ (300000æ¯«ç§’) è‡ªå‹•åˆ·æ–°ä¸€æ¬¡é é¢
st_autorefresh(interval=5 * 60 * 1000, key="auto_refresh")

# --- 2. æ‚¨çš„ GAS API ---
GAS_URL = "https://script.google.com/macros/s/AKfycbwTsM79MMdedizvIcIn7tgwT81VIhj87WM-bvR45QgmMIUsIemmyR_FzMvG3v5LEHEvPw/exec"

# --- 3. åª’é«”é—œéµå­—å­—å…¸ ---
MEDIA_PRESETS = {
    "é›…è™": "https://finance.yahoo.com/news/rssindex",
    "yahoo": "https://finance.yahoo.com/news/rssindex",
    "é‰…äº¨": "https://news.cnyes.com/rss/cat/headline",
    "cnyes": "https://news.cnyes.com/rss/cat/headline",
    "è¯åˆ": "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
    "ç¶“æ¿Ÿæ—¥å ±": "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
    "ä¸­æ™‚": "https://www.chinatimes.com/rss/260410.xml",
    "å·¥å•†": "https://www.chinatimes.com/rss/260410.xml",
    "è‡ªç”±": "https://ec.ltn.com.tw/rss/all.xml",
    "moneydj": "https://www.moneydj.com/rss/xa/mdj_xa_rss.xml",
    "å•†å‘¨": "https://www.businessweekly.com.tw/rss/latest",
    "å•†æ¥­å‘¨åˆŠ": "https://www.businessweekly.com.tw/rss/latest",
    "ç§‘æŠ€": "https://technews.tw/feed/",
    "æ•¸ä½": "https://www.bnext.com.tw/rss"
}

# --- 4. CSS å„ªåŒ– ---
st.markdown("""
    <style>
    html, body, [class*="css"] { font-family: "Microsoft JhengHei", sans-serif; }
    
    /* è‚¡ç¥¨å¡ç‰‡ */
    .compact-card {
        border: 1px solid #ddd; border-radius: 6px;
        padding: 5px 2px; text-align: center;
        background: white; margin-bottom: 5px;
        box-shadow: 1px 1px 2px rgba(0,0,0,0.1);
        min-height: 85px;
    }
    .compact-name { 
        font-size: 15px !important; font-weight: 900; color: #333; margin: 0; line-height: 1.2; 
        white-space: nowrap; overflow: hidden; text-overflow: ellipsis;
    }
    .compact-price { font-size: 18px !important; font-weight: bold; margin: 2px 0; line-height: 1.2;}
    
    /* PChome é¢¨æ ¼æ¦œå–® */
    .rank-title {
        font-size: 18px; font-weight: 900; color: #fff;
        background: linear-gradient(90deg, #d32f2f, #ef5350);
        padding: 8px; border-radius: 5px 5px 0 0;
        margin-top: 15px; text-align: center;
    }
    .rank-box {
        border: 1px solid #ef5350; border-top: none;
        border-radius: 0 0 5px 5px; padding: 5px;
        background: #fff; margin-bottom: 15px;
    }
    .rank-row {
        display: flex; justify-content: space-between; align-items: center;
        padding: 8px 5px; border-bottom: 1px dashed #eee;
    }
    .rank-name { font-size: 16px; font-weight: bold; color: #333; }
    
    /* Yahoo æ–°èåˆ†é¡ */
    .news-category-header {
        background-color: #f1f8ff; color: #1f4e78;
        padding: 8px 12px; border-left: 6px solid #1f4e78;
        font-size: 20px !important; font-weight: 900;
        margin-top: 25px; margin-bottom: 10px;
    }
    .news-item { padding: 12px 0; border-bottom: 1px solid #eee; }
    .news-link {
        text-decoration: none; color: #222;
        font-size: 20px; font-weight: 600;
        line-height: 1.4; display: block; margin-bottom: 6px;
    }
    .news-link:hover { color: #2E86C1; }
    .news-meta { font-size: 13px; color: #888; }
    .news-tag { display: inline-block; background: #eee; color: #555; font-size: 12px; padding: 2px 6px; border-radius: 4px; margin-right: 5px; }

    div[data-testid="column"] { padding: 0 2px !important; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‘µ é˜¿ç¾çš„è‚¡æµ·é¡§å•")
# é¡¯ç¤ºæ›´æ–°æ™‚é–“ï¼Œè®“åª½åª½çŸ¥é“è³‡æ–™æ˜¯æœ€æ–°çš„
st.caption(f"è‡ªå‹•æ›´æ–°å•Ÿç”¨ä¸­ (æ¯5åˆ†é˜) | ä¸Šæ¬¡æ›´æ–°ï¼š{datetime.now().strftime('%H:%M:%S')}")

# --- 5. è³‡æ–™è¨­å®š ---
KEYWORD_MAPPING = {
    "ğŸ“Š ä¸Šå¸‚é¡è‚¡": {
        "åŠå°é«”/é›»å­": ["å°ç©é›»", "è¯ç™¼ç§‘", "è¯é›»", "åŠå°é«”", "æ™¶åœ“", "IC", "é›»å­"],
        "é›»è…¦/å…‰é›»": ["é›»è…¦", "å»£é”", "ç·¯å‰µ", "å…‰é›»", "é¢æ¿", "å‹é”", "ç¾¤å‰µ", "æŠ€å˜‰", "è¯ç¢©", "å®ç¢"],
        "èˆªé‹/é‹è¼¸": ["é•·æ¦®", "é™½æ˜", "è¬æµ·", "èˆªé‹", "èˆªç©º", "è¯èˆª", "é•·æ¦®èˆª", "æ•£è£"],
        "é‡‘è/ä¿éšª": ["é‡‘æ§", "éŠ€è¡Œ", "å¯Œé‚¦", "åœ‹æ³°", "ä¸­ä¿¡", "ç‰å±±", "å…ƒå¤§", "é‡‘è"],
        "æ°´æ³¥/é‹¼éµ/å‚³ç”¢": ["æ°´æ³¥", "å°æ³¥", "äºæ³¥", "é‹¼éµ", "ä¸­é‹¼", "ç´¡ç¹”", "å¡‘è† ", "å°å¡‘"],
        "ç”ŸæŠ€/ç‡Ÿå»º": ["ç”ŸæŠ€", "è—¥", "ç–«è‹—", "ç‡Ÿå»º", "æˆ¿å¸‚", "é é›„", "èˆˆå¯Œç™¼"]
    },
    "ğŸ’¡ æ¦‚å¿µè‚¡": {
        "AI/æ©Ÿå™¨äºº": ["AI", "äººå·¥æ™ºæ…§", "æ©Ÿå™¨äºº", "ä¼ºæœå™¨", "è¼é”", "NVIDIA", "æ•£ç†±", "å¥‡é‹"],
        "è˜‹æœä¾›æ‡‰éˆ": ["è˜‹æœ", "Apple", "iPhone", "iPad", "é´»æµ·", "å¤§ç«‹å…‰", "Type-C"],
        "é›»å‹•è»Š/è»Šé›»": ["é›»å‹•è»Š", "ç‰¹æ–¯æ‹‰", "Tesla", "é›»æ± ", "å……é›»æ¨", "è£•éš†", "é´»è¯", "ADAS"],
        "ç¶ èƒ½/é‡é›»": ["ç¶ èƒ½", "é¢¨é›»", "å¤ªé™½èƒ½", "å„²èƒ½", "è¯åŸ", "å£«é›»", "ä¸­èˆˆé›»"],
        "å…ƒå®‡å®™/ç¶²é€š": ["å…ƒå®‡å®™", "VR", "å®é”é›»", "ç¶²é€š", "æ™ºé‚¦", "WiFi", "5G", "ä½è»Œè¡›æ˜Ÿ"]
    },
    "ğŸ¢ é›†åœ˜è‚¡": {
        "å°ç©é›»é›†åœ˜": ["å°ç©é›»", "ç²¾æ", "å‰µæ„", "ä¸–ç•Œå…ˆé€²"],
        "é´»æµ·é›†åœ˜": ["é´»æµ·", "é´»æº–", "ç¾¤å‰µ", "æ¨ºæ¼¢", "å·¥æ¥­å¯Œè¯"],
        "å°å¡‘é›†åœ˜": ["å°å¡‘", "å—äº", "å°åŒ–", "å°å¡‘åŒ–"],
        "é•·æ¦®é›†åœ˜": ["é•·æ¦®", "æ¦®é‹", "é•·æ¦®èˆª", "é•·æ¦®é‹¼"],
        "åœ‹æ³°/å¯Œé‚¦é›†åœ˜": ["åœ‹æ³°é‡‘", "å¯Œé‚¦é‡‘", "å¯Œé‚¦åª’"],
        "è¯è¯/é æ±é›†åœ˜": ["è¯è¯", "è¯å¼·", "é æ±æ–°", "é å‚³"]
    }
}

HOT_LISTS = {
    "ğŸ”¥ ç†±é–€è¨è«–è‚¡": ["2330.TW", "2317.TW", "3231.TW", "2382.TW", "2603.TW", "2609.TW"], 
    "ğŸ’ äººæ°£ ETF": ["00878.TW", "0056.TW", "0050.TW", "00919.TW", "00929.TW", "00940.TW"], 
    "ğŸ’¡ ç†±é–€æ¦‚å¿µ": ["1519.TW", "1513.TW", "2308.TW", "2454.TW", "6669.TW", "2376.TW"] 
}

STOCK_MAP = {
    "00878": "åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯", "2301": "å…‰å¯¶ç§‘", "2308": "å°é”é›»", "2412": "ä¸­è¯é›»", 
    "2476": "é‰…ç¥¥", "2884": "ç‰å±±é‡‘", "2892": "ç¬¬ä¸€é‡‘", "3034": "è¯è© ", 
    "3035": "æ™ºåŸ", "3363": "ä¸Šè©®", "3715": "å®šç©æŠ•æ§", "4772": "å°ç‰¹åŒ–", 
    "5880": "åˆåº«é‡‘", "6191": "ç²¾æˆç§‘", "6761": "ç©©å¾—", "6788": "è¯æ™¯é›»", 
    "8926": "å°æ±½é›»", "2330": "å°ç©é›»", "2317": "é´»æµ·", "2603": "é•·æ¦®", 
    "2609": "é™½æ˜", "2615": "è¬æµ·", "2454": "è¯ç™¼ç§‘", "3231": "ç·¯å‰µ",
    "0056": "å…ƒå¤§é«˜è‚¡æ¯", "0050": "å…ƒå¤§å°ç£50", "00919": "ç¾¤ç›Šå°ç£ç²¾é¸", "00929": "å¾©è¯ç§‘æŠ€å„ªæ¯",
    "00940": "å…ƒå¤§å°ç£åƒ¹å€¼", "1519": "è¯åŸ", "1513": "ä¸­èˆˆé›»", "1503": "å£«é›»", "2382": "å»£é”", "6669": "ç·¯ç©",
    "2376": "æŠ€å˜‰"
}

# --- 6. æ ¸å¿ƒå‡½æ•¸ ---

def get_list_from_cloud(list_type):
    try:
        response = requests.get(GAS_URL, params={"action": "read", "type": list_type}, timeout=5)
        return response.json() or []
    except: return []

def update_cloud(action, code, list_type, price="0"):
    try: requests.get(GAS_URL, params={"action": action, "code": code, "type": list_type, "price": price}, timeout=2)
    except: pass

def get_name(ticker):
    code = ticker.split(".")[0]
    return STOCK_MAP.get(code, code)

def get_stock_data(ticker_list):
    if not ticker_list: return pd.DataFrame()
    valid = [t for t in ticker_list if t.strip()]
    if not valid: return pd.DataFrame()
    data = []
    try:
        stocks = yf.Tickers(" ".join(valid))
        for t in valid:
            try:
                info = stocks.tickers[t].history(period="5d")
                if len(info) > 0:
                    price = info['Close'].iloc[-1]
                    prev = info['Close'].iloc[-2] if len(info) > 1 else price
                    pct = ((price - prev) / prev) * 100
                    color = "#e53935" if pct >= 0 else "#43a047"
                    sign = "â–²" if pct >= 0 else "â–¼"
                    data.append({
                        "name": get_name(t), "code": t.replace(".TW", "").replace(".TWO", ""),
                        "full_code": t, "price": f"{price:.2f}",
                        "pct": f"{pct:.2f}%", "color": color, "sign": sign
                    })
            except: continue
    except: pass
    return pd.DataFrame(data)

# ã€é—œéµèª¿æ•´ã€‘å°‡å¿«å–æ™‚é–“å¾ 1800 (30åˆ†) æ”¹ç‚º 300 (5åˆ†)ï¼Œé…åˆè‡ªå‹•æ›´æ–°
@st.cache_data(ttl=300)
def fetch_news_waterfall(rss_list):
    buckets = {"ğŸ“Š ä¸Šå¸‚é¡è‚¡": [], "ğŸ’¡ æ¦‚å¿µè‚¡": [], "ğŸ¢ é›†åœ˜è‚¡": [], "ğŸŒ å…¶ä»–å¿«è¨Š": []}
    seen_titles = set()
    
    if not rss_list:
        rss_list = ["https://news.cnyes.com/rss/cat/headline", "https://news.cnyes.com/rss/cat/200"]

    for url in rss_list:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:25]:
                title = entry.title
                if title[:10] in seen_titles: continue
                seen_titles.add(title[:10])
                
                if "yahoo" in url and sum(1 for c in title if '\u4e00' <= c <= '\u9fff') < len(title)*0.3:
                     try: title = GoogleTranslator(source='auto', target='zh-TW').translate(title)
                     except: pass
                
                item = {
                    "title": title, "link": entry.link, 
                    "date": entry.get('published', '')[:16], 
                    "src": feed.feed.get('title', 'å¿«è¨Š')
                }
                
                matched = False
                for sub, kws in KEYWORD_MAPPING["ğŸ“Š ä¸Šå¸‚é¡è‚¡"].items():
                    if any(kw in title for kw in kws):
                        item_copy = item.copy(); item_copy["tag"] = sub; buckets["ğŸ“Š ä¸Šå¸‚é¡è‚¡"].append(item_copy); matched = True; break 
                if not matched:
                    for sub, kws in KEYWORD_MAPPING["ğŸ’¡ æ¦‚å¿µè‚¡"].items():
                        if any(kw in title for kw in kws):
                            item_copy = item.copy(); item_copy["tag"] = sub; buckets["ğŸ’¡ æ¦‚å¿µè‚¡"].append(item_copy); matched = True; break
                if not matched:
                    for sub, kws in KEYWORD_MAPPING["ğŸ¢ é›†åœ˜è‚¡"].items():
                        if any(kw in title for kw in kws):
                            item_copy = item.copy(); item_copy["tag"] = sub; buckets["ğŸ¢ é›†åœ˜è‚¡"].append(item_copy); matched = True; break
                
                if not matched: buckets["ğŸŒ å…¶ä»–å¿«è¨Š"].append(item)
        except: continue
    return buckets

# --- 7. ä»‹é¢ä½ˆå±€ ---

with st.sidebar:
    st.header("âš™ï¸ ç®¡ç†å“¡å¾Œå°")
    
    with st.expander("â• æ–°å¢åˆ°ã€åº«å­˜è‚¡ã€‘"):
        inv_code = st.text_input("ä»£ç¢¼", key="add_inv", placeholder="å¦‚ 2330.TW")
        if st.button("åŠ å…¥åº«å­˜"):
            update_cloud("add", inv_code.upper(), "inventory")
            st.cache_data.clear(); st.rerun()
            
    with st.expander("â• æ–°å¢åˆ°ã€è§€å¯Ÿåå–®ã€‘"):
        watch_code = st.text_input("ä»£ç¢¼", key="add_watch", placeholder="å¦‚ 2603.TW")
        if st.button("åŠ å…¥è§€å¯Ÿ"):
            update_cloud("add", watch_code.upper(), "watchlist")
            st.cache_data.clear(); st.rerun()

    with st.expander("ğŸ“° æ–°å¢ã€æ–°èé »é“ã€‘(æ”¯æ´ä¸­æ–‡)"):
        st.info("è¼¸å…¥ã€Œé›…è™ã€ã€ã€Œé‰…äº¨ã€æˆ–ç›´æ¥è²¼ç¶²å€")
        new_rss_input = st.text_input("åª’é«”åç¨±æˆ–ç¶²å€", key="add_rss_input", placeholder="ä¾‹å¦‚ï¼šé›…è™")
        
        if st.button("åŠ å…¥é »é“"):
            url_to_add = ""
            found_name = ""
            
            if "http" in new_rss_input:
                url_to_add = new_rss_input
            else:
                for key, link in MEDIA_PRESETS.items():
                    if key in new_rss_input:
                        url_to_add = link
                        found_name = key
                        break
            
            if url_to_add:
                update_cloud("add", url_to_add, "news")
                if found_name: st.success(f"å·²è¾¨è­˜ç‚ºã€{found_name}ã€‘ï¼ŒåŠ å…¥æˆåŠŸï¼")
                else: st.success("å·²åŠ å…¥è‡ªè¨‚ç¶²å€ï¼")
                st.cache_data.clear(); st.rerun()
            else:
                st.error("âš ï¸ æ‰¾ä¸åˆ°é€™å€‹åª’é«”ï¼Œè«‹å˜—è©¦è¼¸å…¥ã€Œé›…è™ã€ã€ã€Œé‰…äº¨ã€æˆ–ç›´æ¥è²¼ä¸Šç¶²å€ã€‚")
        
        current_feeds = get_list_from_cloud("news")
        if current_feeds:
            st.write("---")
            st.write("å·²åŠ å…¥çš„é »é“ï¼š")
            for feed in current_feeds:
                display_name = "è‡ªè¨‚ä¾†æº"
                for k, v in MEDIA_PRESETS.items():
                    if v == feed: display_name = k; break
                
                c1, c2 = st.columns([4, 1])
                c1.text(f"{display_name} ({feed[:10]}...)")
                if c2.button("åˆª", key=f"del_rss_{feed}"):
                     update_cloud("remove", feed, "news")
                     st.cache_data.clear(); st.rerun()

    if st.button("ğŸ”„ å¼·åˆ¶æ›´æ–°"): st.cache_data.clear(); st.rerun()

# === ç¬¬ä¸€å±¤ï¼šğŸ’° åª½åª½çš„åº«å­˜ (6æ¬„) ===
c1, c2 = st.columns([3, 1])
with c1: st.subheader("ğŸ’° åª½åª½çš„åº«å­˜")
with c2: 
    if st.button("æ›´æ–°"): st.cache_data.clear(); st.rerun()

inv_list = get_list_from_cloud("inventory")
if inv_list:
    df = get_stock_data(inv_list)
    cols = st.columns(6)
    for i, row in df.iterrows():
        with cols[i%6]:
            st.markdown(f"""
            <div class="compact-card" style="border-left: 4px solid {row['color']};">
                <div class="compact-name" title="{row['name']}">{row['name']}</div>
                <div class="compact-price" style="color:{row['color']}">{row['price']}</div>
                <div style="font-size:12px; font-weight:bold; color:{row['color']}">{row['sign']} {row['pct']}</div>
            </div>""", unsafe_allow_html=True)
            if st.button("âœ–", key=f"d_{row['code']}"): update_cloud("remove", row['full_code'], "inventory"); st.rerun()

# === ç¬¬äºŒå±¤ï¼šğŸ‘€ æœ‰èˆˆè¶£çš„è‚¡ç¥¨ (6æ¬„) ===
st.subheader("ğŸ‘€ æœ‰èˆˆè¶£çš„è‚¡ç¥¨")
watch_list = get_list_from_cloud("watchlist")
if watch_list:
    df_w = get_stock_data(watch_list)
    cols2 = st.columns(6)
    for i, row in df_w.iterrows():
        with cols2[i%6]:
            st.markdown(f"""<div class="compact-card"><div class="compact-name">{row['name']}</div><div class="compact-price" style="color:{row['color']}">{row['price']}</div></div>""", unsafe_allow_html=True)
            if st.button("âœ–", key=f"dw_{row['code']}"): update_cloud("remove", row['full_code'], "watchlist"); st.rerun()
else:
    st.info("ç›®å‰æ²’æœ‰è§€å¯Ÿåå–®ï¼Œè«‹å¾å·¦å´æ–°å¢ã€‚")

# === ç¬¬ä¸‰å±¤ï¼šğŸ† å¸‚å ´ç†±é–€æˆ°æƒ…å®¤ ===
st.markdown("---")
st.subheader("ğŸ† å¸‚å ´ç†±é–€æˆ°æƒ…å®¤")

hot_cols = st.columns(3)
idx = 0
for title, tickers in HOT_LISTS.items():
    with hot_cols[idx]:
        st.markdown(f'<div class="rank-title">{title}</div>', unsafe_allow_html=True)
        df_hot = get_stock_data(tickers)
        html = '<div class="rank-box">'
        for _, row in df_hot.iterrows():
            html += f"""
            <div class="rank-row">
                <span class="rank-name">{row['name']}</span>
                <span class="rank-price" style="color:{row['color']}">{row['sign']} {row['price']}</span>
            </div>"""
        html += '</div>'
        st.markdown(html, unsafe_allow_html=True)
    idx += 1

# === ç¬¬å››å±¤ï¼šğŸ“° ç”¢æ¥­æ–°èç€‘å¸ƒæµ ===
st.markdown("---")
st.subheader("ğŸ—ï¸ ç”¢æ¥­æ–°èå¿«é")

st.markdown("""
<div style="overflow-x:auto; white-space:nowrap; padding-bottom:10px;">
<a href="https://news.cnyes.com/news/cat/headline" target="_blank" style="padding:5px 10px; background:#eee; border-radius:15px; text-decoration:none; margin-right:5px; font-size:14px;">é‰…äº¨é ­æ¢ â†—</a>
<a href="https://news.cnyes.com/news/cat/hotai" target="_blank" style="padding:5px 10px; background:#eee; border-radius:15px; text-decoration:none; margin-right:5px; font-size:14px;">å°è‚¡é€Ÿå ± â†—</a>
<a href="https://tw.stock.yahoo.com/class" target="_blank" style="padding:5px 10px; background:#eee; border-radius:15px; text-decoration:none; margin-right:5px; font-size:14px;">Yahooé¡è‚¡ â†—</a>
</div>
""", unsafe_allow_html=True)

# æŠ“å–é›²ç«¯è‡ªè¨‚æ–°èæº + é è¨­æº
custom_rss = get_list_from_cloud("news")
if not custom_rss:
    active_rss = [
        "https://news.cnyes.com/rss/cat/headline",
        "https://news.cnyes.com/rss/cat/200",
        "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
        "https://finance.yahoo.com/news/rssindex"
    ]
else:
    active_rss = custom_rss

with st.spinner("æ­£åœ¨ç‚ºåª½åª½æ•´ç†æ–°è..."):
    news_buckets = fetch_news_waterfall(active_rss)

cats_order = ["ğŸ“Š ä¸Šå¸‚é¡è‚¡", "ğŸ’¡ æ¦‚å¿µè‚¡", "ğŸ¢ é›†åœ˜è‚¡", "ğŸŒ å…¶ä»–å¿«è¨Š"]

for cat in cats_order:
    items = news_buckets.get(cat, [])
    if items:
        st.markdown(f'<div class="news-category-header">{cat}</div>', unsafe_allow_html=True)
        for n in items[:8]:
            tag_html = f'<span class="news-tag">{n["tag"]}</span>' if "tag" in n else ""
            st.markdown(f"""
            <div class="news-item">
                <a href="{n['link']}" target="_blank" class="news-link">
                    {n['title']}
                </a>
                <div class="news-meta">
                    {tag_html} {n['src']} â€¢ {n['date']}
                </div>
            </div>
            """, unsafe_allow_html=True)

st.markdown("<br><br>", unsafe_allow_html=True)
