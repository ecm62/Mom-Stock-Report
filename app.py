import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
import requests
from deep_translator import GoogleTranslator
from datetime import datetime, timedelta, timezone
from streamlit_autorefresh import st_autorefresh

# --- 1. é é¢èˆ‡æ™‚å€è¨­å®š ---
st.set_page_config(layout="wide", page_title="é˜¿ç¾çš„è‚¡æµ·é¡§å•", initial_sidebar_state="collapsed")
st_autorefresh(interval=5 * 60 * 1000, key="auto_refresh")

TW_TZ = timezone(timedelta(hours=8))
def get_tw_time():
    return datetime.now(TW_TZ).strftime('%Y-%m-%d %H:%M')

# --- 2. GAS API ---
# è«‹ç¢ºèªé€™æ˜¯å¦ç‚ºæ‚¨æœ€æ–°éƒ¨ç½² (æœ‰é¸ã€Œå»ºç«‹æ–°ç‰ˆæœ¬ã€) çš„ç¶²å€
GAS_URL = "https://script.google.com/macros/s/AKfycbwTsM79MMdedizvIcIn7tgwT81VIhj87WM-bvR45QgmMIUsIemmyR_FzMvG3v5LEHEvPw/exec"

# --- 3. åª’é«”èˆ‡ CSS è¨­å®š ---
MEDIA_PRESETS = {
    "é›…è™": "https://finance.yahoo.com/news/rssindex", "é‰…äº¨": "https://news.cnyes.com/rss/cat/headline",
    "è¯åˆ": "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money", "ç¶“æ¿Ÿ": "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
    "moneydj": "https://www.moneydj.com/rss/xa/mdj_xa_rss.xml", "å•†å‘¨": "https://www.businessweekly.com.tw/rss/latest",
    "ç§‘æŠ€": "https://technews.tw/feed/"
}

# ä¿®å¾© CSS æ ¼å¼ï¼Œé¿å…é¡¯ç¤ºäº‚ç¢¼
st.markdown("""
<style>
html, body, [class*="css"] { font-family: "Microsoft JhengHei", sans-serif; }
.compact-card { border: 1px solid #ddd; border-radius: 6px; padding: 5px 2px; text-align: center; background: white; margin-bottom: 5px; box-shadow: 1px 1px 2px rgba(0,0,0,0.1); min-height: 80px; }
.compact-name { font-size: 15px !important; font-weight: 900; color: #333; margin: 0; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;}
.compact-price { font-size: 18px !important; font-weight: bold; margin: 0;}
.news-category-header { background-color: #e3f2fd; color: #0d47a1; padding: 8px 12px; border-left: 6px solid #0d47a1; font-size: 20px !important; font-weight: 900; margin-top: 20px; margin-bottom: 5px; border-radius: 4px; }
.news-item-compact { padding: 6px 0; border-bottom: 1px dashed #ccc; line-height: 1.3; }
.news-link-text { text-decoration: none; color: #222; font-size: 18px !important; font-weight: 600; display: block; }
.news-link-text:hover { color: #d32f2f; }
.news-meta-compact { font-size: 12px; color: #666; margin-top: 2px;}
.rank-title { font-size: 18px; font-weight: 900; color: #fff; background: linear-gradient(90deg, #d32f2f, #ef5350); padding: 8px; border-radius: 5px 5px 0 0; margin-top: 15px; text-align: center; }
.rank-box { border: 1px solid #ef5350; border-top: none; border-radius: 0 0 5px 5px; padding: 5px; background: #fff; margin-bottom: 15px; }
.rank-row { display: flex; justify-content: space-between; align-items: center; padding: 8px 5px; border-bottom: 1px dashed #eee; }
.rank-name { font-size: 16px; font-weight: bold; color: #333; }
.stButton > button { width: 100%; border-radius: 8px; font-weight: bold; font-size: 18px;}
div[data-testid="column"] { padding: 0 2px !important; }
</style>
""", unsafe_allow_html=True)

# --- 4. ç™»å…¥é‚è¼¯ (å«è‡ªå‹•ç™»å…¥) ---
query_params = st.query_params
url_user = query_params.get("user", "")
url_pass = query_params.get("password", "")

if 'logged_in' not in st.session_state: st.session_state['logged_in'] = False
if 'user_name' not in st.session_state: st.session_state['user_name'] = ""

def verify_user(username, password):
    try:
        response = requests.get(GAS_URL, params={"action": "login", "user": username, "password": password}, timeout=5)
        res = response.json()
        return res.get("status") == "success"
    except: return False

def register_user(username, password):
    try:
        response = requests.get(GAS_URL, params={"action": "signup", "user": username, "password": password}, timeout=5)
        return response.json()
    except: return {"status": "error", "msg": "é€£ç·šå¤±æ•—"}

# è‡ªå‹•ç™»å…¥å˜—è©¦
if not st.session_state['logged_in'] and url_user and url_pass:
    if verify_user(url_user, url_pass):
        st.session_state['logged_in'] = True
        st.session_state['user_name'] = url_user

# ç™»å…¥é–˜é“ UI
if not st.session_state['logged_in']:
    st.title("ğŸ” æ­¡è¿ä¾†åˆ°è‚¡æµ·é¡§å•")
    st.caption("è«‹ç™»å…¥ä»¥å­˜å–æ‚¨çš„å°ˆå±¬è³‡æ–™")
    
    tab1, tab2 = st.tabs(["ğŸ”‘ ç™»å…¥", "ğŸ“ è¨»å†Š"])
    
    with tab1:
        with st.form("login_form"):
            user_in = st.text_input("å¸³è™Ÿ", value=url_user)
            pass_in = st.text_input("å¯†ç¢¼", type="password")
            submitted = st.form_submit_button("ç™»å…¥", type="primary")
            if submitted:
                if verify_user(user_in, pass_in):
                    st.session_state['logged_in'] = True
                    st.session_state['user_name'] = user_in
                    st.query_params["user"] = user_in
                    st.rerun()
                else:
                    st.error("å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤ (è«‹ç¢ºèª GAS æ˜¯å¦å·²ç™¼å¸ƒç‚ºã€æ–°ç‰ˆæœ¬ã€)")
    
    with tab2:
        with st.form("signup_form"):
            new_user = st.text_input("è¨­å®šå¸³è™Ÿ")
            new_pass = st.text_input("è¨­å®šå¯†ç¢¼", type="password")
            submit_reg = st.form_submit_button("è¨»å†Š")
            if submit_reg and new_user and new_pass:
                res = register_user(new_user, new_pass)
                if res.get("status") == "success":
                    st.success("è¨»å†ŠæˆåŠŸï¼è«‹åˆ‡æ›åˆ°ç™»å…¥é ç±¤ç™»å…¥ã€‚")
                else:
                    st.error(f"è¨»å†Šå¤±æ•—ï¼š{res.get('msg')}")
    st.stop()

# =========================================================
# ä¸»ç¨‹å¼
# =========================================================

current_user = st.session_state['user_name']

# å´é‚Šæ¬„
with st.sidebar:
    st.header(f"ğŸ‘¤ {current_user}")
    
    my_link = f"?user={current_user}"
    with st.expander("ğŸ”— å–å¾—åˆ†äº«é€£çµ"):
        st.caption("åˆ†äº«æ­¤é€£çµçµ¦æœ‹å‹ (å°æ–¹éœ€è¼¸å…¥å¯†ç¢¼)")
        st.code(f"https://share.streamlit.io/...(æ‚¨çš„ç¶²å€)...{my_link}", language="text")

    if st.button("ç™»å‡º"):
        st.session_state['logged_in'] = False
        st.query_params.clear()
        st.rerun()
    st.divider()

    st.header("âš™ï¸ è‚¡ç¥¨ç®¡ç†")
    with st.expander("â• æ–°å¢åˆ°ã€åº«å­˜è‚¡ã€‘"):
        inv_code = st.text_input("ä»£ç¢¼", key="add_inv", placeholder="å¦‚ 2330.TW")
        if st.button("åŠ å…¥åº«å­˜"):
            try: requests.get(GAS_URL, params={"action": "add", "code": inv_code.upper(), "type": "inventory", "user": current_user}, timeout=2)
            except: pass
            st.cache_data.clear(); st.rerun()
            
    with st.expander("â• æ–°å¢åˆ°ã€è§€å¯Ÿåå–®ã€‘"):
        watch_code = st.text_input("ä»£ç¢¼", key="add_watch", placeholder="å¦‚ 2603.TW")
        if st.button("åŠ å…¥è§€å¯Ÿ"):
            try: requests.get(GAS_URL, params={"action": "add", "code": watch_code.upper(), "type": "watchlist", "user": current_user}, timeout=2)
            except: pass
            st.cache_data.clear(); st.rerun()

    with st.expander("ğŸ“° æ–°å¢ã€æ–°èé »é“ã€‘"):
        new_rss = st.text_input("è¼¸å…¥ã€Œé‰…äº¨ã€æˆ–ç¶²å€", key="rss_in")
        if st.button("åŠ å…¥é »é“"):
            url = new_rss
            if new_rss in MEDIA_PRESETS: url = MEDIA_PRESETS[new_rss]
            try: requests.get(GAS_URL, params={"action": "add", "code": url, "type": "news", "user": current_user}, timeout=2)
            except: pass
            st.cache_data.clear(); st.rerun()
    
    if st.button("ğŸ”„ å¼·åˆ¶æ›´æ–°"): st.cache_data.clear(); st.rerun()

# æ¨™é¡Œèˆ‡æ›´æ–°å€
c_title, c_btn = st.columns([3, 1])
with c_title:
    st.title(f"ğŸ‘µ {current_user} çš„è‚¡æµ·é¡§å•") 
    st.caption(f"å°ç£æ™‚é–“ï¼š{get_tw_time()} | è‡ªå‹•æ›´æ–°ä¸­...")
with c_btn:
    st.write("") 
    if st.button("ğŸ”´ é»æˆ‘æ›´æ–°è‚¡åƒ¹", type="primary"):
        st.cache_data.clear()
        st.rerun()

# --- è³‡æ–™è™•ç†å‡½æ•¸ ---
KEYWORD_MAPPING = {
    "ğŸ¤– AI èˆ‡åŠå°é«”": ["å°ç©é›»", "è¯é›»", "è¯ç™¼ç§‘", "æ—¥æœˆå…‰", "AI", "åŠå°é«”", "æ™¶åœ“", "è¼é”", "NVIDIA", "CoWoS", "å…ˆé€²å°è£", "ä¼ºæœå™¨", "ç·¯å‰µ", "å»£é”", "æŠ€å˜‰", "æ™ºåŸ", "ä¸–èŠ¯", "å‰µæ„"],
    "ğŸ—ï¸ é‹¼éµèˆ‡æ°´æ³¥": ["ä¸­é‹¼", "ä¸­é´»", "å¤§æˆé‹¼", "é‹¼éµ", "å°æ³¥", "äºæ³¥", "æ°´æ³¥", "ç»é™¶", "è±èˆˆ", "é‹¼åƒ¹", "åŸºå»º", "æ˜¥é›¨", "ç‡è¼"],
    "ğŸš¢ èˆªé‹èˆ‡é‹è¼¸": ["é•·æ¦®", "é™½æ˜", "è¬æµ·", "èˆªé‹", "è²¨æ«ƒ", "æ•£è£", "BDI", "èˆªç©º", "è¯èˆª", "é•·æ¦®èˆª", "æ˜Ÿå®‡", "é‹åƒ¹", "æ…§æ´‹", "è£•æ°‘"],
    "ğŸš— æ±½è»Šèˆ‡ä¾›æ‡‰éˆ": ["è£•éš†", "å’Œæ³°è»Š", "ä¸­è¯è»Š", "æ±½è»Š", "é›»å‹•è»Š", "ç‰¹æ–¯æ‹‰", "Tesla", "é´»è¯", "å……é›»æ¨", "è»Šç”¨", "æ±é™½", "å ¤ç¶­è¥¿", "AM", "å¸å¯¶", "å’Œå¤§"],
    "ğŸ’° é‡‘èèˆ‡éŠ€è¡Œ": ["é‡‘æ§", "éŠ€è¡Œ", "å£½éšª", "å¯Œé‚¦", "åœ‹æ³°", "ä¸­ä¿¡", "ç‰å±±", "å…†è±", "å°æ–°", "å‡æ¯", "é™æ¯", "è‚¡åˆ©", "é…æ¯", "ç¬¬ä¸€é‡‘", "è¯å—é‡‘"],
    "âš¡ é‡é›»èˆ‡ç¶ èƒ½": ["è¯åŸ", "å£«é›»", "ä¸­èˆˆé›»", "äºåŠ›", "é‡é›»", "ç¶ èƒ½", "é¢¨é›»", "å¤ªé™½èƒ½", "å„²èƒ½", "å°é›»", "é›»ç¶²", "æ£®å´´", "ä¸–ç´€é‹¼"],
    "ğŸ’Š ç”ŸæŠ€èˆ‡é˜²ç–«": ["ç”ŸæŠ€", "è—¥", "ç–«è‹—", "åˆä¸€", "é«˜ç«¯", "ç¾æ™‚", "ä¿ç‘", "é†«ç™‚", "é•·è–", "è—¥è¯è—¥"],
    "ğŸ  ç‡Ÿå»ºèˆ‡æˆ¿ç”¢": ["ç‡Ÿå»º", "æˆ¿åœ°ç”¢", "æˆ¿å¸‚", "é é›„", "èˆˆå¯Œç™¼", "åœ‹ç”¢", "é å”®å±‹", "æ½¤æ³°", "å† å¾·"]
}

HOT_LISTS = {
    "ğŸ”¥ ç†±é–€è¨è«–": ["2330.TW", "2317.TW", "3231.TW", "2382.TW", "2603.TW", "2609.TW"], 
    "ğŸ’ äººæ°£ ETF": ["00878.TW", "0056.TW", "0050.TW", "00919.TW", "00929.TW", "00940.TW"], 
    "ğŸ’¡ ç„¦é»æ¦‚å¿µ": ["1519.TW", "1513.TW", "2308.TW", "2454.TW", "6669.TW", "2376.TW"] 
}

STOCK_MAP = {"00878": "åœ‹æ³°é«˜è‚¡æ¯", "2330": "å°ç©é›»", "2317": "é´»æµ·", "2603": "é•·æ¦®", "2609": "é™½æ˜", "2454": "è¯ç™¼ç§‘", "3231": "ç·¯å‰µ", "0056": "å…ƒå¤§é«˜è‚¡æ¯", "0050": "å°ç£50", "00919": "ç¾¤ç›Šç²¾é¸", "00940": "å°ç£åƒ¹å€¼", "1519": "è¯åŸ", "1513": "ä¸­èˆˆé›»", "1503": "å£«é›»", "2382": "å»£é”", "6669": "ç·¯ç©", "2376": "æŠ€å˜‰", "2002": "ä¸­é‹¼", "1101": "å°æ³¥", "2201": "è£•éš†", "2412":"ä¸­è¯é›»", "2308":"å°é”é›»", "2881":"å¯Œé‚¦é‡‘", "2882":"åœ‹æ³°é‡‘"}

def get_list_from_cloud(list_type, user):
    try:
        response = requests.get(GAS_URL, params={"action": "read", "type": list_type, "user": user}, timeout=5)
        return response.json() or []
    except: return []

def update_cloud_remove(code, list_type, user):
    try: requests.get(GAS_URL, params={"action": "remove", "code": code, "type": list_type, "user": user}, timeout=2)
    except: pass

def get_name(ticker):
    code = ticker.split(".")[0]
    return STOCK_MAP.get(code, code)

# ä¿®å¾©èªæ³•éŒ¯èª¤ï¼šç¢ºä¿è®Šæ•¸åç¨±èˆ‡é‚è¼¯æ­£ç¢º
def get_stock_data(ticker_list):
    if not ticker_list: return pd.DataFrame()
    valid = [t for t in ticker_list if t.strip()]
    if not valid: return pd.DataFrame()
    data = []
    try:
        stocks = yf.Tickers(" ".join(valid))
        for t in valid:
            try:
                info = stocks.tickers[t].history(period="5d")
                if len(info) > 0:
                    price = info['Close'].iloc[-1]
                    prev = info['Close'].iloc[-2] if len(info) > 1 else price
                    pct = ((price - prev) / prev) * 100
                    color = "#e53935" if pct >= 0 else "#43a047"
                    sign = "â–²" if pct >= 0 else "â–¼"
                    data.append({
                        "name": get_name(t), "code": t.replace(".TW", "").replace(".TWO", ""),
                        "full_code": t, "price": f"{price:.2f}",
                        "pct": f"{pct:.2f}%", "color": color, "sign": sign
                    })
            except: continue
    except: pass
    return pd.DataFrame(data)

@st.cache_data(ttl=300) 
def fetch_and_filter_news(user_rss_urls):
    buckets = {key: [] for key in KEYWORD_MAPPING.keys()}
    buckets["ğŸŒ å…¶ä»–é ­æ¢"] = []
    seen = set()
    
    default_rss = [
        "https://news.cnyes.com/rss/cat/headline", 
        "https://news.cnyes.com/rss/cat/200",
        "https://news.cnyes.com/rss/cat/hotai",
        "https://finance.yahoo.com/news/rssindex",
        "https://money.udn.com/rssfeed/news/1001/5590/5591?ch=money",
        "https://www.moneydj.com/rss/xa/mdj_xa_rss.xml",
        "https://technews.tw/feed/"
    ]
    if user_rss_urls: default_rss.extend(user_rss_urls)
    final_rss = list(set(default_rss))

    for url in final_rss:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:80]: 
                title = entry.title
                if title[:10] in seen: continue
                seen.add(title[:10])
                
                if "yahoo" in url and sum(1 for c in title if '\u4e00' <= c <= '\u9fff') < len(title)*0.3:
                     try: title = GoogleTranslator(source='auto', target='zh-TW').translate(title)
                     except: pass
                
                item = {"title": title, "link": entry.link, "date": entry.get('published', '')[:16], "src": feed.feed.get('title', 'å¿«è¨Š')}
                
                matched = False
                for category, keywords in KEYWORD_MAPPING.items():
                    if any(kw in title for kw in keywords):
                        buckets[category].append(item); matched = True; break 
                if not matched: buckets["ğŸŒ å…¶ä»–é ­æ¢"].append(item)
        except: continue
    return buckets

# 1. åº«å­˜
st.subheader(f"ğŸ’° {current_user} çš„åº«å­˜")
inv_list = get_list_from_cloud("inventory", current_user)
if inv_list:
    df = get_stock_data(inv_list)
    cols = st.columns(6)
    for i, row in df.iterrows():
        with cols[i%6]:
            st.markdown(f"""
            <div class="compact-card" style="border-left: 4px solid {row['color']};">
                <div class="compact-name" title="{row['name']}">{row['name']}</div>
                <div class="compact-price" style="color:{row['color']}">{row['price']}</div>
                <div style="font-size:12px; font-weight:bold; color:{row['color']}">{row['sign']} {row['pct']}</div>
            </div>""", unsafe_allow_html=True)
            if st.button("âœ–", key=f"d_{row['code']}"): 
                update_cloud_remove(row['full_code'], "inventory", current_user)
                st.cache_data.clear(); st.rerun()
else: st.info("æ¸…å–®ç©ºç™½ï¼Œè«‹å¾å´é‚Šæ¬„æ–°å¢ã€‚")

# 2. è§€å¯Ÿ
st.subheader(f"ğŸ‘€ {current_user} çš„è§€å¯Ÿåå–®")
watch_list = get_list_from_cloud("watchlist", current_user)
if watch_list:
    df_w = get_stock_data(watch_list)
    cols2 = st.columns(6)
    for i, row in df_w.iterrows():
        with cols2[i%6]:
            st.markdown(f"""<div class="compact-card"><div class="compact-name">{row['name']}</div><div class="compact-price" style="color:{row['color']}">{row['price']}</div></div>""", unsafe_allow_html=True)
            if st.button("âœ–", key=f"dw_{row['code']}"): 
                update_cloud_remove(row['full_code'], "watchlist", current_user)
                st.cache_data.clear(); st.rerun()

# 3. ç†±é–€
st.markdown("---")
st.subheader("ğŸ† å¸‚å ´ç†±é–€æˆ°æƒ…å®¤")
hot_cols = st.columns(3)
idx = 0
for title, tickers in HOT_LISTS.items():
    with hot_cols[idx]:
        st.markdown(f'<div class="rank-title">{title}</div>', unsafe_allow_html=True)
        df_hot = get_stock_data(tickers)
        html = '<div class="rank-box">'
        for _, row in df_hot.iterrows():
            html += f"""<div class="rank-row"><span class="rank-name">{row['name']}</span><span class="rank-price" style="color:{row['color']}">{row['sign']} {row['price']}</span></div>"""
        html += '</div>'
        st.markdown(html, unsafe_allow_html=True)
    idx += 1

# 4. æ–°è
st.markdown("---")
st.subheader("ğŸ—ï¸ ç”¢æ¥­æ–°èå¿«é")
user_rss = get_list_from_cloud("news", current_user)
with st.spinner("æ­£åœ¨æœå°‹æœ€æ–°æ–°è..."):
    news_buckets = fetch_and_filter_news(user_rss)

display_order = ["ğŸ¤– AI èˆ‡åŠå°é«”", "ğŸ—ï¸ é‹¼éµèˆ‡æ°´æ³¥", "ğŸš¢ èˆªé‹èˆ‡é‹è¼¸", "ğŸš— æ±½è»Šèˆ‡ä¾›æ‡‰éˆ", "ğŸ’° é‡‘èèˆ‡éŠ€è¡Œ", "âš¡ é‡é›»èˆ‡ç¶ èƒ½", "ğŸ’Š ç”ŸæŠ€èˆ‡é˜²ç–«", "ğŸ  ç‡Ÿå»ºèˆ‡æˆ¿ç”¢", "ğŸŒ å…¶ä»–é ­æ¢"]

for category in display_order:
    items = news_buckets.get(category, [])
    if items:
        st.markdown(f'<div class="news-category-header">{category} ({len(items)})</div>', unsafe_allow_html=True)
        for n in items: 
            st.markdown(f"""
            <div class="news-item-compact">
                <a href="{n['link']}" target="_blank" class="news-link-text">
                    {n['title']}
                </a>
                <div class="news-meta-compact">
                    {n['src']} â€¢ {n['date']}
                </div>
            </div>
            """, unsafe_allow_html=True)

st.markdown("<br><br>", unsafe_allow_html=True)
