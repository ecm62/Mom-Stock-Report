import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
from deep_translator import GoogleTranslator
from datetime import datetime

# --- è¨­å®šé é¢ ---
st.set_page_config(layout="wide", page_title="é˜¿ç¾çš„è‚¡æµ·æ±ºç­–å ±")

# --- CSS å„ªåŒ– (åŠ å¤§å­—é«”) ---
st.markdown("""
    <style>
    .big-font { font-size:30px !important; font-weight:bold; color: #E74C3C; }
    .medium-font { font-size:24px !important; font-weight:bold; }
    .news-title { font-size:20px !important; font-weight:bold; color: #2E86C1; text-decoration: none; }
    .news-box { border: 1px solid #ddd; padding: 15px; border-radius: 10px; margin-bottom: 10px; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‘µ é˜¿ç¾çš„è‚¡æµ·æ±ºç­–é¡§å•")
st.markdown(f"**æ›´æ–°æ™‚é–“ï¼š** {datetime.now().strftime('%Y-%m-%d %H:%M')} (è«‹æŒ‰å³ä¸Šè§’é¸å–®çš„ Rerun æ›´æ–°)")

# --- å´é‚Šæ¬„åƒæ•¸ ---
st.sidebar.header("âš™ï¸ è¨­å®šå€")
my_stocks_str = st.sidebar.text_area("å·²æŒæœ‰è‚¡ç¥¨ (ä»£ç¢¼ç”¨é€—è™Ÿéš”é–‹)", "2330.TW, 2317.TW, 00878.TW, 2412.TW")
watch_stocks_str = st.sidebar.text_area("è§€å¯Ÿåå–®", "2603.TW, 1101.TW, 1301.TW, 2618.TW")

# --- æ ¸å¿ƒå‡½æ•¸ ---

@st.cache_data(ttl=3600)
def translate_to_chinese(text):
    """å°‡è‹±æ–‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡ (å¿«å–1å°æ™‚)"""
    try:
        # å¦‚æœæ˜¯ä¸­æ–‡å°±ä¸ç”¨ç¿»
        for char in text:
            if '\u4e00' <= char <= '\u9fff':
                return text
        return GoogleTranslator(source='auto', target='zh-TW').translate(text)
    except:
        return text

def get_stock_data(tickers_input):
    """æŠ“å–è‚¡åƒ¹èˆ‡æ¼²è·Œ"""
    if not tickers_input: return pd.DataFrame()
    ticker_list = [t.strip().upper() for t in tickers_input.split(",") if t.strip()]
    
    data = []
    for t in ticker_list:
        try:
            stock = yf.Ticker(t)
            hist = stock.history(period="5d")
            if len(hist) > 0:
                price = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2] if len(hist) > 1 else price
                change = price - prev
                pct = (change / prev) * 100
                
                # ç°¡å–®ç‹€æ…‹åˆ¤æ–·
                state = "ğŸ”´ å¤§æ¼²" if pct >= 3 else ("ğŸŸ¢ å¤§è·Œ" if pct <= -3 else "âšª ç›¤æ•´")
                if pct > 0: color_style = 'color: red;'
                elif pct < 0: color_style = 'color: green;'
                else: color_style = 'color: gray;'

                data.append({
                    "ä»£ç¢¼": t.replace(".TW", ""),
                    "ç¾åƒ¹": f"{price:.2f}",
                    "æ¼²è·Œ": f"{change:.2f}",
                    "å¹…åº¦%": f"{pct:.2f}%",
                    "ç‹€æ…‹": state,
                    "raw_pct": pct # ç”¨æ–¼æ’åº
                })
        except: continue
    return pd.DataFrame(data)

def get_news(url, count=5, need_trans=False):
    """æŠ“å–ä¸¦è™•ç†æ–°è"""
    feed = feedparser.parse(url)
    news_list = []
    for entry in feed.entries[:count]:
        title = entry.title
        if need_trans:
            title = translate_to_chinese(title)
        news_list.append({"title": title, "link": entry.link, "date": entry.get('published', '')[:16]})
    return news_list

# --- ä»‹é¢ä½ˆå±€ ---

# 1. æŒè‚¡èˆ‡è§€å¯Ÿå€
col1, col2 = st.columns(2)

with col1:
    st.markdown('<p class="medium-font">ğŸ’° åª½åª½çš„æŒè‚¡</p>', unsafe_allow_html=True)
    df_own = get_stock_data(my_stocks_str)
    if not df_own.empty:
        # ä½¿ç”¨ Styler è®“æ¼²è·Œè®Šè‰²
        st.dataframe(df_own.drop(columns=['raw_pct']), use_container_width=True, hide_index=True)

with col2:
    st.markdown('<p class="medium-font">ğŸ‘€ é‡é»è§€å¯Ÿ</p>', unsafe_allow_html=True)
    df_watch = get_stock_data(watch_stocks_str)
    if not df_watch.empty:
        st.dataframe(df_watch.drop(columns=['raw_pct']), use_container_width=True, hide_index=True)

st.divider()

# 2. ç”¢æ¥­æ’è¡Œæ¦œ
st.markdown("## ğŸ† ç”¢æ¥­é¾é ­æ¼²è·Œæ’è¡Œ")
SECTORS = {
    "æ°´æ³¥/å‚³ç”¢": ["1101.TW", "1102.TW", "2105.TW"],
    "å¡‘åŒ–": ["1301.TW", "1303.TW", "1326.TW"],
    "èˆªé‹": ["2603.TW", "2609.TW", "2615.TW"],
    "é›»å­/AI": ["2330.TW", "2317.TW", "2454.TW", "3231.TW", "2382.TW"],
    "é‡‘è": ["2881.TW", "2882.TW", "2891.TW"]
}

# æŠ“å–æ‰€æœ‰ç”¢æ¥­è‚¡
all_sector_tickers = ",".join([",".join(v) for v in SECTORS.values()])
df_sector = get_stock_data(all_sector_tickers)

if not df_sector.empty:
    c1, c2 = st.columns(2)
    with c1:
        st.error("ğŸ”¥ å¼·å‹¢è‚¡ (æ¼²æœ€å¤š)")
        top_gain = df_sector.sort_values(by="raw_pct", ascending=False).head(5)
        st.table(top_gain[['ä»£ç¢¼', 'ç¾åƒ¹', 'å¹…åº¦%', 'ç‹€æ…‹']])
    with c2:
        st.success("ğŸ§Š å¼±å‹¢è‚¡ (è·Œæœ€å¤š)")
        top_loss = df_sector.sort_values(by="raw_pct", ascending=True).head(5)
        st.table(top_loss[['ä»£ç¢¼', 'ç¾åƒ¹', 'å¹…åº¦%', 'ç‹€æ…‹']])

st.divider()

# 3. æ–°èå€
st.markdown("## ğŸ“° å…¨çƒè²¡ç¶“æ–°è (ä¸­è­¯ç‰ˆ)")

tab1, tab2, tab3 = st.tabs(["ğŸ‡¹ğŸ‡¼ å°ç£ç„¦é»", "ğŸ‡ºğŸ‡¸ ç¾åœ‹è²¡ç¶“", "ğŸ¤– AI ç§‘æŠ€"])

with tab1:
    news = get_news("https://news.cnyes.com/rss/cat/200", need_trans=False)
    for n in news:
        st.markdown(f'<div class="news-box"><a href="{n["link"]}" target="_blank" class="news-title">{n["title"]}</a><br><small>{n["date"]}</small></div>', unsafe_allow_html=True)

with tab2:
    with st.spinner("æ­£åœ¨ç¿»è­¯ç¾åœ‹æ–°è...è«‹ç¨ç­‰"):
        news = get_news("https://finance.yahoo.com/news/rssindex", need_trans=True)
        for n in news:
            st.markdown(f'<div class="news-box"><a href="{n["link"]}" target="_blank" class="news-title">{n["title"]}</a><br><small>{n["date"]}</small></div>', unsafe_allow_html=True)

with tab3:
    with st.spinner("æ­£åœ¨ç¿»è­¯ç§‘æŠ€æ–°è...è«‹ç¨ç­‰"):
        news = get_news("https://techcrunch.com/feed/", need_trans=True)
        for n in news:
            st.markdown(f'<div class="news-box"><a href="{n["link"]}" target="_blank" class="news-title">{n["title"]}</a><br><small>{n["date"]}</small></div>', unsafe_allow_html=True)

st.markdown("---")
st.caption("Produced by Dr. Yang for Mom")
